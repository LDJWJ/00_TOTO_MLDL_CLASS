{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01-0.2886.hdf5',\n",
       " '01-0.2910.hdf5',\n",
       " '01-0.2958.hdf5',\n",
       " '01-18.2494.hdf5',\n",
       " '01-2.2923.hdf5',\n",
       " '02-0.2294.hdf5',\n",
       " '02-0.2398.hdf5',\n",
       " '02-0.2454.hdf5',\n",
       " '03-0.1987.hdf5',\n",
       " '03-0.2048.hdf5',\n",
       " '03-0.2185.hdf5',\n",
       " '04-0.1779.hdf5',\n",
       " '04-0.1888.hdf5',\n",
       " '04-0.2011.hdf5',\n",
       " '05-0.1674.hdf5',\n",
       " '05-0.1696.hdf5',\n",
       " '05-0.1908.hdf5',\n",
       " '06-0.1542.hdf5',\n",
       " '06-0.1639.hdf5',\n",
       " '06-0.1730.hdf5',\n",
       " '07-0.1526.hdf5',\n",
       " '07-0.1539.hdf5',\n",
       " '07-0.1629.hdf5',\n",
       " '08-0.1424.hdf5',\n",
       " '08-0.1474.hdf5',\n",
       " '08-0.1569.hdf5',\n",
       " '09-0.1387.hdf5',\n",
       " '09-0.1486.hdf5',\n",
       " '10-0.1360.hdf5',\n",
       " '10-0.1371.hdf5',\n",
       " '10-0.1458.hdf5',\n",
       " '11-0.1305.hdf5',\n",
       " '11-0.1366.hdf5',\n",
       " '11-0.1384.hdf5',\n",
       " '12-0.1330.hdf5',\n",
       " '12-0.1377.hdf5',\n",
       " '13-0.1270.hdf5',\n",
       " '13-0.1291.hdf5',\n",
       " '13-0.1330.hdf5',\n",
       " '14-0.1239.hdf5',\n",
       " '14-0.1283.hdf5',\n",
       " '14-0.1308.hdf5',\n",
       " '15-0.1220.hdf5',\n",
       " '15-0.1263.hdf5',\n",
       " '16-0.1206.hdf5',\n",
       " '16-0.1239.hdf5',\n",
       " '16-0.1266.hdf5',\n",
       " '17-0.1191.hdf5',\n",
       " '17-0.1223.hdf5',\n",
       " '18-0.1167.hdf5',\n",
       " '18-0.1204.hdf5',\n",
       " '18-0.1256.hdf5',\n",
       " '19-0.1203.hdf5',\n",
       " '19-0.1252.hdf5',\n",
       " '20-0.1191.hdf5',\n",
       " '20-0.1244.hdf5',\n",
       " '21-0.1162.hdf5',\n",
       " '21-0.1165.hdf5',\n",
       " '21-0.1243.hdf5',\n",
       " '23-0.1197.hdf5',\n",
       " '26-0.1158.hdf5',\n",
       " '28-0.1144.hdf5']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"08-0.1424.hdf5\" (mode r)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f = h5py.File('./model/21-0.1165.hdf5', 'r')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_weights', 'optimizer_weights']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(f.keys())\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 group \"/model_weights\" (2 members)>\n",
      "<HDF5 group \"/optimizer_weights\" (2 members)>\n"
     ]
    }
   ],
   "source": [
    "print( f['model_weights'] )\n",
    "print( f['optimizer_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hdf5 파일 확인\n",
    "def getWeight(layerName, fileName):\n",
    "    with h5py.File(fileName, mode='r') as f:\n",
    "        for key in f:\n",
    "            print(\"1 step:\",key, f[key])\n",
    "            f1 = f[key]\n",
    "            for key1 in f1:\n",
    "                print(\"  2 step:\", key1, f1[key1])\n",
    "                f2 = f1[key1]\n",
    "                for key2 in f2:\n",
    "                    print(\"   3 step:\", key2, f2[key2])\n",
    "                    f3 = f2[key2]\n",
    "                    # print(type(f3))\n",
    "                    if str(type(f3))==\"<class 'h5py._hl.group.Group'>\":\n",
    "                        for key3 in f3:\n",
    "                            print(\"     4 step:\", key3, f3[key3])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 step: model_weights <HDF5 group \"/model_weights\" (2 members)>\n",
      "  2 step: dense_7 <HDF5 group \"/model_weights/dense_7\" (1 members)>\n",
      "   3 step: dense_7 <HDF5 group \"/model_weights/dense_7/dense_7\" (2 members)>\n",
      "     4 step: bias:0 <HDF5 dataset \"bias:0\": shape (32,), type \"<f4\">\n",
      "     4 step: kernel:0 <HDF5 dataset \"kernel:0\": shape (784, 32), type \"<f4\">\n",
      "  2 step: dense_8 <HDF5 group \"/model_weights/dense_8\" (1 members)>\n",
      "   3 step: dense_8 <HDF5 group \"/model_weights/dense_8/dense_8\" (2 members)>\n",
      "     4 step: bias:0 <HDF5 dataset \"bias:0\": shape (10,), type \"<f4\">\n",
      "     4 step: kernel:0 <HDF5 dataset \"kernel:0\": shape (32, 10), type \"<f4\">\n",
      "1 step: optimizer_weights <HDF5 group \"/optimizer_weights\" (2 members)>\n",
      "  2 step: Adam_1 <HDF5 group \"/optimizer_weights/Adam_1\" (1 members)>\n",
      "   3 step: iterations:0 <HDF5 dataset \"iterations:0\": shape (), type \"<i8\">\n",
      "  2 step: training_1 <HDF5 group \"/optimizer_weights/training_1\" (1 members)>\n",
      "   3 step: Adam <HDF5 group \"/optimizer_weights/training_1/Adam\" (12 members)>\n",
      "     4 step: m_0_1:0 <HDF5 dataset \"m_0_1:0\": shape (784, 32), type \"<f4\">\n",
      "     4 step: m_1_1:0 <HDF5 dataset \"m_1_1:0\": shape (32,), type \"<f4\">\n",
      "     4 step: m_2_1:0 <HDF5 dataset \"m_2_1:0\": shape (32, 10), type \"<f4\">\n",
      "     4 step: m_3_1:0 <HDF5 dataset \"m_3_1:0\": shape (10,), type \"<f4\">\n",
      "     4 step: v_0_1:0 <HDF5 dataset \"v_0_1:0\": shape (784, 32), type \"<f4\">\n",
      "     4 step: v_1_1:0 <HDF5 dataset \"v_1_1:0\": shape (32,), type \"<f4\">\n",
      "     4 step: v_2_1:0 <HDF5 dataset \"v_2_1:0\": shape (32, 10), type \"<f4\">\n",
      "     4 step: v_3_1:0 <HDF5 dataset \"v_3_1:0\": shape (10,), type \"<f4\">\n",
      "     4 step: vhat_0_1:0 <HDF5 dataset \"vhat_0_1:0\": shape (1,), type \"<f4\">\n",
      "     4 step: vhat_1_1:0 <HDF5 dataset \"vhat_1_1:0\": shape (1,), type \"<f4\">\n",
      "     4 step: vhat_2_1:0 <HDF5 dataset \"vhat_2_1:0\": shape (1,), type \"<f4\">\n",
      "     4 step: vhat_3_1:0 <HDF5 dataset \"vhat_3_1:0\": shape (1,), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "getWeight(\"dense\", \"./model/02-0.2454.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "def isGroup(obj):\n",
    "    if isinstance(obj, h5py.Group):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isDataset(obj):\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetFromGroup(datasets, obj):\n",
    "    \n",
    "    if isGroup(obj):\n",
    "        for key in obj:\n",
    "            x = obj[key]\n",
    "            getDatasetFromGroup(datasets, x)\n",
    "    else:\n",
    "        datasets.append(obj)\n",
    "\n",
    "def getWeightsForLayer(layerName, fileName):\n",
    "    weights = []\n",
    "    with h5py.File(fileName, mode='r') as f:\n",
    "        for key in f:\n",
    "            if layerName in key:\n",
    "                obj = f[key]\n",
    "                datasets = []\n",
    "                getDatasetFromGroup(datasets, obj)\n",
    "                \n",
    "                for dataset in datasets:\n",
    "                    w = np.array(dataset)\n",
    "                    weights.append(w)\n",
    "    return weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "weights = getWeightsForLayer(\"dense1\", \"./model/21-0.1165.hdf5\")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
